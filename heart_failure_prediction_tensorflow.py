# -*- coding: utf-8 -*-
"""heart_failure_prediction_tensorflow.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-CeCuok_crbz-CI63SIA0y2a1HxXi2lc

# Heart Failure Classification Problem
"""

import tensorflow as tf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

tf.__version__

file = ('/content/heart.csv')
  
df = pd.read_csv(file)
df

from sklearn.compose import make_column_transformer
from sklearn.preprocessing import MinMaxScaler, OneHotEncoder
from sklearn.model_selection import train_test_split

# Create a column transformer 
ct = make_column_transformer(
    (MinMaxScaler(), ["Age", "RestingBP", "Cholesterol", "MaxHR", "Oldpeak"]), # turn all values in these columns between 0 and 1
    (OneHotEncoder(handle_unknown="ignore"), ["Sex", "ST_Slope", "ExerciseAngina", "RestingECG", "ChestPainType"])
)

# Create X & y
X = df.drop("HeartDisease", axis=1)
y = df["HeartDisease"]

# Build our train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2 , random_state=42)

# Fit the column transformer to our training data
ct.fit(X_train)

# Transform training and test data with normalization (MinMaxScaler) and OneHotEncoder
X_train_normal = ct.transform(X_train)
X_test_normal = ct.transform(X_test)

X_train.loc[0]

X_train_normal[0]

tf.random.set_seed(42)
callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=8)

model = tf.keras.Sequential([
    tf.keras.layers.Dense(100, activation="gelu"),
    tf.keras.layers.Dense(10, activation="gelu"),
    tf.keras.layers.Dense(1, activation="sigmoid")
])

model.compile(loss=tf.keras.losses.BinaryCrossentropy(),
              optimizer=tf.keras.optimizers.Adam(lr=0.001),
              metrics=["accuracy"])

history = model.fit(X_train_normal, y_train, callbacks=[callback], epochs=500)

model.evaluate(X_test_normal, y_test)

# Plot history
pd.DataFrame(history.history).plot(figsize=(10, 7))
plt.ylabel("loss")
plt.xlabel("epochs");

from sklearn.metrics import confusion_matrix

# Make predictions
y_pred = model.predict(X_test_normal)

y_test[:10], y_pred[:10]

# Convert our prediction probabilities to binary format and view the first 10 
y_pred_binary = tf.round(y_pred)
y_pred_binary[:10]

import itertools

# Create the confusion metrix
cm = confusion_matrix(y_test, y_pred_binary)
cm_norm = cm.astype("float") / cm.sum(axis=1)[:, np.newaxis] # normalize our confusion metrix
n_classes = cm.shape[0]

# Let's prettify it
fig, ax = plt.subplots(figsize=(10, 10))
# Create a matrix plot
cax = ax.matshow(cm, cmap=plt.cm.Blues)
fig.colorbar(cax)

# Create classes
classes = False

if classes:
  labels = classes
else:
  labels = np.arange(cm.shape[0])

# Label axes
ax.set(title="Confusion Matrix",
       xlabel="Predicted",
       ylabel="True Label",
       xticks=np.arange(n_classes),
       yticks=np.arange(n_classes),
       xticklabels=labels,
       yticklabels=labels)

# Set x-axis labels to bottom
ax.xaxis.set_label_position("bottom")
ax.xaxis.tick_bottom()

# Adjust label size
ax.yaxis.label.set_size(20)
ax.xaxis.label.set_size(20)
ax.title.set_size(25)



# Set threshold for different colors
threshold = (cm.max() + cm.min()) / 2.

# Plot the text on each cell
for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
  plt.text(j, i, f"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)",
           horizontalalignment="center",
           color="white" if cm[i, j] > threshold else "black",
           size=15)



